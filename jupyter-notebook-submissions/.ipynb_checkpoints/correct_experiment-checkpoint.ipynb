{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Detect if we are in the TIRA sandbox\n",
    "# Install the required dependencies if we are not in the sandbox.\n",
    "if 'TIRA_DATASET_ID' not in os.environ:\n",
    "    !pip3 install python-terrier tira==0.0.88 ir_datasets\n",
    "else:\n",
    "    print('We are in the TIRA sandbox.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "print('importing libraries...')\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "from load_dataset import load_dataset\n",
    "from create_index import create_index\n",
    "from create_model import create_model\n",
    "from generate_custom_stopwords_improved import generate_custom_stopwords_improved\n",
    "print('Done. Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from create_index import create_index\n",
    "from load_dataset import load_dataset\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "folder_path = './stopwordlists/merged/'\n",
    "pattern = 'merged_*.txt'\n",
    "merged_stopword_files = glob.glob(folder_path + pattern)\n",
    "training_dataset = 'ir-lab-jena-leipzig-wise-2023/training-20231104-training'\n",
    "load_dataset_result = load_dataset(training_dataset)\n",
    "queries = load_dataset(training_dataset)['queries']\n",
    "\n",
    "for improved_stopwords in merged_stopword_files:\n",
    "    run_name = improved_stopwords.replace(\"./stopwordlists/merged/\", '')\n",
    "    config = {'stopwords': improved_stopwords, 'stemmer': None}\n",
    "    print(\"RUN FOR STOPWORDS:\", run_name)\n",
    "\n",
    "    improved_index = create_index(load_dataset(training_dataset)['documents'], config)\n",
    "    print(\"index created\")\n",
    "\n",
    "    improved_model = create_model(improved_index)\n",
    "    print(\"model created\")\n",
    "\n",
    "    run = improved_model(queries)\n",
    "\n",
    "    output_dir = 'runs/training/improved-stopwords'\n",
    "    run_output_dir = output_dir + '/' + run_name\n",
    "\n",
    "    !rm -Rf {run_output_dir}\n",
    "    !mkdir -p {run_output_dir}\n",
    "\n",
    "    persist_and_normalize_run(run, run_name, run_output_dir)\n",
    "\n",
    "    !touch {run_output_dir}/config.txt\n",
    "\n",
    "    with open(f\"{run_output_dir}/config.txt\", 'w') as output_file:\n",
    "        output_file.write(f\"{json.dumps(config)} -- stopwords length = {len(improved_stopwords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runs/training/improved-stopwords/merged_17711.txt/run.txt', 'runs/training/improved-stopwords/merged_3.txt/run.txt', 'runs/training/improved-stopwords/merged_610.txt/run.txt', 'runs/training/improved-stopwords/merged_987.txt/run.txt', 'runs/training/improved-stopwords/merged_8.txt/run.txt', 'runs/training/improved-stopwords/merged_1597.txt/run.txt', 'runs/training/improved-stopwords/merged_233.txt/run.txt', 'runs/training/improved-stopwords/merged_89.txt/run.txt', 'runs/training/improved-stopwords/merged_10946.txt/run.txt', 'runs/training/improved-stopwords/merged_13.txt/run.txt', 'runs/training/improved-stopwords/merged_2584.txt/run.txt', 'runs/training/improved-stopwords/merged_2.txt/run.txt', 'runs/training/improved-stopwords/merged_21.txt/run.txt', 'runs/training/improved-stopwords/merged_377.txt/run.txt', 'runs/training/improved-stopwords/merged_34.txt/run.txt', 'runs/training/improved-stopwords/merged_55.txt/run.txt', 'runs/training/improved-stopwords/merged_6765.txt/run.txt', 'runs/training/improved-stopwords/merged_4181.txt/run.txt', 'runs/training/improved-stopwords/merged_144.txt/run.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "folder_path = 'runs/training/improved-stopwords/'\n",
    "pattern = '**/run.txt'\n",
    "files = glob.glob(folder_path + pattern)\n",
    "\n",
    "print(files)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare to english long text without stemmer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "file:  runs/training/improved-stopwords/merged_17711.txt/run.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file not set yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------DONE-----------------\n",
      "file:  runs/training/improved-stopwords/merged_3.txt/run.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile: \u001b[39m\u001b[38;5;124m\"\u001b[39m, file)\n\u001b[0;32m---> 42\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mevaluate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_qrels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining-20231104-training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------DONE-----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m, in \u001b[0;36mevaluate_run\u001b[0;34m(qrels, runFile)\u001b[0m\n\u001b[1;32m     16\u001b[0m run \u001b[38;5;241m=\u001b[39m TrecRun(runFile)\n\u001b[1;32m     17\u001b[0m trec_eval \u001b[38;5;241m=\u001b[39m TrecEval(run, qrels)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrec_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m: run\u001b[38;5;241m.\u001b[39mget_runid(),\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnDCG@10\u001b[39m\u001b[38;5;124m'\u001b[39m: trec_eval\u001b[38;5;241m.\u001b[39mget_ndcg(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m: trec_eval\u001b[38;5;241m.\u001b[39mget_precision()\n\u001b[1;32m     29\u001b[0m }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:110\u001b[0m, in \u001b[0;36mTrecEval.evaluate_all\u001b[0;34m(self, per_query)\u001b[0m\n\u001b[1;32m    108\u001b[0m bpref_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_bpref(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, per_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, trec_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    109\u001b[0m rprec_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rprec(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, per_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, trec_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 110\u001b[0m recip_rank_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reciprocal_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrec_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m rows \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    113\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_id},\n\u001b[1;32m    114\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_ret\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_retrieved_documents(per_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDCG_1000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: ndcg[\u001b[38;5;241m1000\u001b[39m]},\n\u001b[1;32m    141\u001b[0m ]\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# TODO: iprec_at_recall_LEVEL is missing from the default trec_eval metrics\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:280\u001b[0m, in \u001b[0;36mTrecEval.get_reciprocal_rank\u001b[0;34m(self, depth, per_query, trec_eval, removeUnjudged)\u001b[0m\n\u001b[1;32m    277\u001b[0m     run \u001b[38;5;241m=\u001b[39m onlyjudged[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trec_eval:\n\u001b[0;32m--> 280\u001b[0m     trecformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    281\u001b[0m     topX \u001b[38;5;241m=\u001b[39m trecformat\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead(depth)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:6941\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6934\u001b[0m         \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[1;32m   6935\u001b[0m         \u001b[38;5;66;03m# expected List[ndarray]\u001b[39;00m\n\u001b[1;32m   6936\u001b[0m         keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6937\u001b[0m             Series(k, name\u001b[38;5;241m=\u001b[39mname)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   6938\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (k, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, by)\n\u001b[1;32m   6939\u001b[0m         ]\n\u001b[0;32m-> 6941\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlexsort_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\n\u001b[1;32m   6943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6944\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[1;32m   6945\u001b[0m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[1;32m   6947\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(by[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/sorting.py:425\u001b[0m, in \u001b[0;36mlexsort_indexer\u001b[0;34m(keys, orders, na_position, key, codes_given)\u001b[0m\n\u001b[1;32m    422\u001b[0m     shape\u001b[38;5;241m.\u001b[39mappend(mask_n)\n\u001b[1;32m    423\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(codes)\n\u001b[0;32m--> 425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexer_from_factorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/sorting.py:304\u001b[0m, in \u001b[0;36mindexer_from_factorized\u001b[0;34m(labels, shape, compress)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexer_from_factorized\u001b[39m(\n\u001b[1;32m    302\u001b[0m     labels, shape: Shape, compress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    303\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]:\n\u001b[0;32m--> 304\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_group_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxnull\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compress:\n\u001b[1;32m    307\u001b[0m         ngroups \u001b[38;5;241m=\u001b[39m (ids\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mand\u001b[39;00m ids\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/sorting.py:193\u001b[0m, in \u001b[0;36mget_group_index\u001b[0;34m(labels, shape, sort, xnull)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         stride \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m lshape[i]\n\u001b[0;32m--> 193\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels[i] \u001b[38;5;241m*\u001b[39m stride\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xnull:  \u001b[38;5;66;03m# exclude nulls\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     mask \u001b[38;5;241m=\u001b[39m labels[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from trectools import TrecRun, TrecQrel, TrecEval\n",
    "from tira.rest_api_client import Client\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "tira = Client()\n",
    "\n",
    "folder_path = 'runs/training/improved-stopwords/'\n",
    "pattern = '**/run.txt'\n",
    "files = glob(folder_path + pattern)\n",
    "\n",
    "\n",
    "def load_qrels(dataset):\n",
    "    return TrecQrel(tira.download_dataset('ir-lab-jena-leipzig-wise-2023', dataset, truth_dataset=True) + '/qrels.txt')\n",
    "\n",
    "def evaluate_run(qrels, runFile):\n",
    "    run = TrecRun(runFile)\n",
    "    trec_eval = TrecEval(run, qrels)\n",
    "\n",
    "    print(trec_eval.evaluate_all())\n",
    "\n",
    "    return {\n",
    "        'run': run.get_runid(),\n",
    "        'nDCG@10': trec_eval.get_ndcg(depth=10),\n",
    "        'nDCG@10 (unjudgedRemoved)': trec_eval.get_ndcg(depth=10, removeUnjudged=True),\n",
    "        'MAP': trec_eval.get_map(depth=10),\n",
    "        'MRR': trec_eval.get_reciprocal_rank(),\n",
    "        'P@10': trec_eval.get_precision(depth=10),\n",
    "        'P': trec_eval.get_precision()\n",
    "    }\n",
    "\n",
    "def test_model(runFile):\n",
    "    training_qrels = load_qrels('training-20231104-training')\n",
    "\n",
    "    print(\"Overall performance:\\n\")\n",
    "    print(evaluate_run(training_qrels, runFile))\n",
    "    print(\"\\n\")\n",
    "\n",
    "result = []\n",
    "\n",
    "for file in files:\n",
    "    print(\"file: \", file)\n",
    "    result += [evaluate_run(load_qrels('training-20231104-training'), file)]\n",
    "    print(\"-----------------DONE-----------------\")\n",
    "\n",
    "print(\"Reference:\")\n",
    "reference_file = 'runs/standard_stopwords/run.txt'\n",
    "result += [evaluate_run(load_qrels('training-20231104-training'), reference_file)]\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.sort_values('nDCG@10', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file not set yet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'run': 'merged_17711.txt',\n",
       " 'nDCG@10': 0.17477708457067012,\n",
       " 'nDCG@10 (unjudgedRemoved)': 0.5296970226402502,\n",
       " 'MAP': 0.11660141778037744,\n",
       " 'MRR': 0.26498239884607894,\n",
       " 'P@10': 0.09150521609538004,\n",
       " 'P': 0.0032742175856929957}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_run(qrels, runFile):\n",
    "    run = TrecRun(runFile)\n",
    "    trec_eval = TrecEval(run, qrels)\n",
    "\n",
    "    ps = {}\n",
    "    ndcg = {}\n",
    "        for v in [5, 10, 15, 20, 30, 100, 200, 500, 1000]:\n",
    "            ps[v] = self.get_precision(depth=v, per_query=False, trec_eval=True)\n",
    "            ndcg[v] = self.get_ndcg(depth=v, per_query=False, trec_eval=True)\n",
    "        map_ = self.get_map(depth=10000, per_query=False, trec_eval=True)\n",
    "        gm_map_ = self.get_geometric_map(depth=10000, trec_eval=True)\n",
    "        bpref_ = self.get_bpref(depth=1000, per_query=False, trec_eval=True)\n",
    "        rprec_ = self.get_rprec(depth=1000, per_query=False, trec_eval=True)\n",
    "        recip_rank_ = self.get_reciprocal_rank(depth=1000, per_query=False, trec_eval=True)\n",
    "\n",
    "    print(trec_eval.evaluate_all())\n",
    "\n",
    "    return {\n",
    "        'run': run.get_runid(),\n",
    "        'nDCG@10': trec_eval.get_ndcg(depth=10),\n",
    "        'nDCG@10 (unjudgedRemoved)': trec_eval.get_ndcg(depth=10, removeUnjudged=True),\n",
    "        'MAP': trec_eval.get_map(depth=10),\n",
    "        'MRR': trec_eval.get_reciprocal_rank(),\n",
    "        'P@10': trec_eval.get_precision(depth=10),\n",
    "        'P': trec_eval.get_precision()\n",
    "    }\n",
    "\n",
    "\n",
    "evaluate_run(load_qrels('training-20231104-training'), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = './stopwordlists/merged/'\n",
    "pattern = 'merged_*.txt'\n",
    "merged_stopword_files = glob.glob(folder_path + pattern)\n",
    "\n",
    "print(merged_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
