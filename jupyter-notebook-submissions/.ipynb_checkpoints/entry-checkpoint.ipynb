{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
      "Requirement already satisfied: tira==0.0.88 in /usr/local/lib/python3.10/dist-packages (0.0.88)\n",
      "Requirement already satisfied: ir_datasets in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
      "Requirement already satisfied: docker==6.*,>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tira==0.0.88) (6.1.3)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /usr/local/lib/python3.10/dist-packages (from tira==0.0.88) (2.31.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tira==0.0.88) (2.1.1)\n",
      "Requirement already satisfied: packaging>=14.0 in /usr/local/lib/python3.10/dist-packages (from docker==6.*,>=6.0.0->tira==0.0.88) (23.2)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker==6.*,>=6.0.0->tira==0.0.88) (1.6.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==6.*,>=6.0.0->tira==0.0.88) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira==0.0.88) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira==0.0.88) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira==0.0.88) (3.3.1)\n",
      "Requirement already satisfied: chest in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.6.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.11.3)\n",
      "Requirement already satisfied: matchpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.0)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-terrier) (4.66.1)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.2.14)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.1)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.26.1)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.3)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
      "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (6.0.1)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (3.2.3)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.3.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.12.2)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.1.12)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.6)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.3.2)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.9.3)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.1.6)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.2)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir_datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.10/dist-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.3)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tira==0.0.88) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira==0.0.88) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira==0.0.88) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->python-terrier) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->python-terrier) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Detect if we are in the TIRA sandbox\n",
    "# Install the required dependencies if we are not in the sandbox.\n",
    "if 'TIRA_DATASET_ID' not in os.environ:\n",
    "    !pip3 install python-terrier tira==0.0.88 ir_datasets\n",
    "else:\n",
    "    print('We are in the TIRA sandbox.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing libraries...\n",
      "Due to execution in TIRA, I have patched ir_datasets to always return the single input dataset mounted to the sandbox.\n",
      "Done. Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "print('importing libraries...')\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "from load_dataset import load_dataset\n",
    "from create_index import create_index\n",
    "from create_model import create_model\n",
    "from generate_custom_stopwords import generate_custom_stopwords\n",
    "print('Done. Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "Load ir_dataset \"ir-lab-jena-leipzig-wise-2023/training-20231104-training\" from tira.\n",
      "data load\n",
      "I will use a custom stopwords list at ./stopwordlists/custom_stopwords.txt\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "Load ir_dataset \"ir-lab-jena-leipzig-wise-2023/training-20231104-training\" from tira.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "index created\n",
      "model created\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"runs/training/custom-stopwords-without-stemmer-14-12-2023-15-37\".\n",
      "Done. run file is stored under \"runs/training/custom-stopwords-without-stemmer-14-12-2023-15-37/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "training_dataset = 'ir-lab-jena-leipzig-wise-2023/training-20231104-training'\n",
    "\n",
    "# load data\n",
    "load_dataset_result = load_dataset(training_dataset)\n",
    "documents, queries = load_dataset_result['documents'], load_dataset_result['queries']\n",
    "print(\"data load\")\n",
    "\n",
    "# generate stopwords\n",
    "# generate_custom_stopwords(documents)\n",
    "# print(\"generated stopwords\")\n",
    "\n",
    "# create index\n",
    "stopwords = './stopwordlists/custom_stopwords.txt'\n",
    "if not os.path.exists(stopwords):\n",
    "        raise ValueError('Could not find stopwords file at %s' % stopwords)\n",
    "\n",
    "print('I will use a custom stopwords list at %s' % stopwords)\n",
    "index = create_index(load_dataset(training_dataset)['documents'], \n",
    "                     {'stopwords': stopwords, 'stemmer': None})\n",
    "print(\"index created\")\n",
    "\n",
    "# create model\n",
    "model = create_model(index)\n",
    "print(\"model created\")\n",
    "\n",
    "# run model\n",
    "run_name = \"stopwords-from-non-relevant-files-without-stemmer\"\n",
    "system = f\"{run_name}-{datetime.now().strftime('%d-%m-%Y-%H-%M')}\"\n",
    "run = model(queries)\n",
    "\n",
    "output_dir = 'runs/training'\n",
    "\n",
    "run_output_dir = output_dir + '/' + system\n",
    "\n",
    "!rm -Rf {run_output_dir}\n",
    "!mkdir -p {run_output_dir}\n",
    "\n",
    "persist_and_normalize_run(run, system, run_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos\n",
    "- play with inverted index and look at results = index(type=IndexingType.SINGLEPASS)\n",
    "\n",
    "# solved \n",
    "- combine static stopword list with custom stopwords \n",
    "    - could be done as test but would not be really fitting to our research question\n",
    "- apply stopwords to queries\n",
    "    - Answer Maik: in PyTerrier, the stopword configuration is part of the index, so if you build the index using a certain stopwordlist, it should automatically apply it to the queries.\n",
    "\n",
    "\n",
    "- bigger size of stopwords\n",
    "- other method of stopwords (idf or normalized)\n",
    "- do evaluation for validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance original model\n",
    "- nDCG@10: 0.1773804215063869\n",
    "- nDCG@10 (unjudgedRemoved): 0.5367157810929261\n",
    "- MAP: 0.1186555257944954\n",
    "- MRR': 0.2628142657723083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "Overall performance:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run': 'custom-stopwords-without-stemmer-14-12-2023-15-37', 'nDCG@10': 0.17477708457067012, 'nDCG@10 (unjudgedRemoved)': 0.5296970226402502, 'MAP': 0.11660141778037744, 'MRR': 0.26498239884607894, 'P@10': 0.09150521609538004, 'P': 0.0032742175856929957}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from trectools import TrecRun, TrecQrel, TrecEval\n",
    "from tira.rest_api_client import Client\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "tira = Client()\n",
    "\n",
    "\n",
    "def load_qrels(dataset):\n",
    "    return TrecQrel(tira.download_dataset('ir-lab-jena-leipzig-wise-2023', dataset, truth_dataset=True) + '/qrels.txt')\n",
    "\n",
    "def evaluate_run(qrels, runFile):\n",
    "    run = TrecRun(runFile)\n",
    "    trec_eval = TrecEval(run, qrels)\n",
    "\n",
    "    return {\n",
    "        'run': run.get_runid(),\n",
    "        'nDCG@10': trec_eval.get_ndcg(depth=10),\n",
    "        'nDCG@10 (unjudgedRemoved)': trec_eval.get_ndcg(depth=10, removeUnjudged=True),\n",
    "        'MAP': trec_eval.get_map(depth=10),\n",
    "        'MRR': trec_eval.get_reciprocal_rank(),\n",
    "        'P@10': trec_eval.get_precision(depth=10),\n",
    "        'P': trec_eval.get_precision()\n",
    "    }\n",
    "\n",
    "def test_model(runFile):\n",
    "    training_qrels = load_qrels('training-20231104-training')\n",
    "\n",
    "    print(\"Overall performance:\\n\")\n",
    "    print(evaluate_run(training_qrels, runFile))\n",
    "    print(\"\\n\")\n",
    "\n",
    "test_model(f\"{run_output_dir}/run.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument\n",
    "\n",
    "- perfect stopword list\n",
    "    - contains all words that do not contribute meaning\n",
    "    - does not contain words that contribute meaning\n",
    "\n",
    "- imperfect stopword list\n",
    "    - contains words that contribute meaning \n",
    "        - means reduced retrieval effectiveness bec. informative word omitted from retrieval process\n",
    "    - does not contain enough words that do not contribute meaning \n",
    "        - means reduced retrieval effectiveness bec. documents that are less specific to the query would be retrieved\n",
    "\n",
    "- standart stopword list\n",
    "    - probably does not contain words that contribute meaning as its very basic\n",
    "    - potentially contains not enough words that do not contribute meaning\n",
    "\n",
    "- custom stopword list\n",
    "    - enhancing the standart stopword list with words that are not contributing meaning and are specific to our dataset \n",
    "    - these words are the most common words found in retrived relevant documents \n",
    "        - because these files are relevant and terms that frequently occur in these documents potentially do not contribute much meaning\n",
    "\n",
    "If we imagine a perfect stopword list, such a list would contain all terms from a document collection \n",
    "    that do not contribute informative meaning to a document\n",
    "and no terms from a document collection \n",
    "    that do contribute informative meaning to a document\n",
    "On the other hand an imperfect stopword list would contain either \n",
    "    words that contribute informative meaning (I)\n",
    "or  not all words that do not contribute informative meaning (II)\n",
    "or  a mixture of both.\n",
    "All of these cases would result in reduced retrieval effectiveness as \n",
    "    a large amount of documents that are less specific to a given query would be retrieved (II) \n",
    "or  documents that are specific to a given query would not be retrieved (I)\n",
    "\n",
    "As we currently use a standard stopword list from <tbd> such a list is unlikely to contain words that contribute meaning in our document collection as it simply contains the most frequent words of english language.\n",
    "However this standard stopword list may potentially contain too little stopwords as our document collection might have a specific vocabulary unlike classic english language.\n",
    "\n",
    "Thats why we conjecture that \n",
    "    enhancing a standard stopword list with a custom stopword list, would improve the retrieval effectiveness of our retrieval model.\n",
    "\n",
    "We derive this custom stopword list by searching for the most common terms in the relevant retrieved documents from a retrieval run with the standard stopword list. \n",
    "\n",
    "# Algorithm\n",
    "1. do retrieval with standard stopword list\n",
    "2. examine all relevant retrieved documents `RD`\n",
    "    - make a list of all terms in `RD` and assign each term how often they occur in the `RD`\n",
    "    - choose a threshold which number of occurences mark stopwords (see other paper for method)\n",
    "    - create a list with all terms over threshold\n",
    "3. merge custom stopword list with standart stopword list\n",
    "4. compare performance of standart, custom and merged stopword list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:\n",
    "- no real changes in performance when trying to just apply other stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m trec_eval \u001b[38;5;241m=\u001b[39m TrecEval(run, training_qrels)\n\u001b[1;32m     16\u001b[0m relevant_retrieved_documents \u001b[38;5;241m=\u001b[39m trec_eval\u001b[38;5;241m.\u001b[39mget_relevant_retrieved_documents()\n\u001b[0;32m---> 18\u001b[0m index_from_relevant_retrieved \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelevant_retrieved_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstopwords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstemmer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m lexicon \u001b[38;5;241m=\u001b[39m index_from_relevant_retrieved\u001b[38;5;241m.\u001b[39mgetLexicon()\n\u001b[1;32m     21\u001b[0m term_frequencies \u001b[38;5;241m=\u001b[39m [(term, le\u001b[38;5;241m.\u001b[39mgetFrequency()) \u001b[38;5;28;01mfor\u001b[39;00m term, le \u001b[38;5;129;01min\u001b[39;00m lexicon]\n",
      "File \u001b[0;32m/workspace/create_index.py:12\u001b[0m, in \u001b[0;36mcreate_index\u001b[0;34m(documents, config)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_index\u001b[39m(documents, config):\n\u001b[1;32m      5\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mIterDictIndexer(\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m         overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         stemmer\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstemmer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 12\u001b[0m     index_ref \u001b[38;5;241m=\u001b[39m indexer\u001b[38;5;241m.\u001b[39mindex(({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocno\u001b[39m\u001b[38;5;124m'\u001b[39m: i\u001b[38;5;241m.\u001b[39mdoc_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: i\u001b[38;5;241m.\u001b[39mtext} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m documents))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pt\u001b[38;5;241m.\u001b[39mIndexFactory\u001b[38;5;241m.\u001b[39mof(index_ref)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "from trectools import TrecRun, TrecQrel, TrecEval\n",
    "from tira.rest_api_client import Client\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "tira = Client()\n",
    "\n",
    "def load_qrels(dataset):\n",
    "    return TrecQrel(tira.download_dataset('ir-lab-jena-leipzig-wise-2023', dataset, truth_dataset=True) + '/qrels.txt')\n",
    "\n",
    "training_qrels = load_qrels('training-20231104-training')\n",
    "runFile = \"runs/training/simple-stopwords-without-stemmer-14-12-2023-15-27/run.txt\"\n",
    "\n",
    "run = TrecRun(runFile)\n",
    "trec_eval = TrecEval(run, training_qrels)\n",
    "\n",
    "relevant_retrieved_documents = trec_eval.get_relevant_retrieved_documents()\n",
    "\n",
    "index_from_relevant_retrieved = create_index(relevant_retrieved_documents, {'stopwords': None, 'stemmer': None})\n",
    "\n",
    "lexicon = index_from_relevant_retrieved.getLexicon()\n",
    "term_frequencies = [(term, le.getFrequency()) for term, le in lexicon]\n",
    "sorted_term_frequencies = sorted(term_frequencies, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# write result to file\n",
    "file_path = './stopwordlists/stopwords_from_relevant_retrieved.txt'\n",
    "\n",
    "##### examine the correct threshold\n",
    "##### choose the threshold: max difference between frequency of two terms F(r) and F(r+1)\n",
    "stopword_list_length = 100\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "        file.write(\"\")\n",
    "\n",
    "with open(file_path, 'a') as file:\n",
    "        for term, le in sorted_term_frequencies[:stopword_list_length]:\n",
    "            string_to_append = f\"{term}\\n\"\n",
    "            file.write(string_to_append)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           query q0            docid  rel\n",
      "0      q06223196  0  doc062200112743    0\n",
      "1      q06223196  0  doc062200205250    0\n",
      "2      q06223196  0  doc062200101983    0\n",
      "3      q06223196  0  doc062200204465    1\n",
      "4      q06223196  0  doc062200115614    0\n",
      "...          ... ..              ...  ...\n",
      "9651  q062225197  0  doc062200205276    0\n",
      "9652  q062225197  0  doc062200107121    1\n",
      "9653  q062225197  0  doc062200204419    0\n",
      "9654  q062225197  0  doc062200103774    0\n",
      "9655  q062225197  0  doc062200110087    0\n",
      "\n",
      "[9656 rows x 4 columns]\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "Load ir_dataset \"ir-lab-jena-leipzig-wise-2023/training-20231104-training\" from tira.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "No settings given in /root/.tira/.tira-settings.json. I will use defaults.\n",
      "TirexQuery(query_id='q062228', text='airport', title='airport', query='airport', description=None, narrative=None)\n",
      "            qid                       query\n",
      "0     q06223196                 car shelter\n",
      "1       q062228                     airport\n",
      "2       q062287        antivirus comparison\n",
      "3     q06223261              free antivirus\n",
      "4       q062291            orange antivirus\n",
      "..          ...                         ...\n",
      "667  q062224914             tax garden shed\n",
      "668  q062224961              land of france\n",
      "669  q062225030   find my training pole job\n",
      "670  q062225194                     gpl car\n",
      "671  q062225197                cheapest car\n",
      "\n",
      "[672 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_qrels.qrels_data)\n",
    "# run.get_top_documents('airport', 10)\n",
    "\n",
    "from tira.third_party_integrations import ir_datasets\n",
    "import pyterrier as pt\n",
    "\n",
    "training_dataset = 'ir-lab-jena-leipzig-wise-2023/training-20231104-training'\n",
    "\n",
    "queries = pt.io.read_topics(ir_datasets.topics_file(training_dataset), format='trecxml')\n",
    "\n",
    "dataset = ir_datasets.load(training_dataset)\n",
    "topics = dataset.queries_iter()\n",
    "\n",
    "documents = dataset.docs_iter()\n",
    "\n",
    "first_topic = list(topics)[1]\n",
    "\n",
    "print(first_topic)\n",
    "\n",
    "run.get_top_documents(first_topic.query_id, 10)\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "qrels = training_qrels.qrels_data.values.tolist()\n",
    "\n",
    "queryIdIndex = 0\n",
    "docIdIndex = 2\n",
    "relevanceIndex = 3\n",
    "\n",
    "\n",
    "# Filter relevant documents\n",
    "relevant_documents = [item for item in qrels if item[relevanceIndex] == 1]\n",
    "\n",
    "# Filter relevant retrieved documents\n",
    "relevant_retrieved_documents = []\n",
    "for item in relevant_documents:\n",
    "    query_id, doc_id = item[queryIdIndex], item[docIdIndex]\n",
    "    is_document_retrieved_in_top_10 = doc_id in run.get_top_documents(query_id, 10)\n",
    "\n",
    "    if is_document_retrieved_in_top_10:\n",
    "        relevant_retrieved_documents.append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc062200205493',\n",
       " 'doc062200111596',\n",
       " 'doc062200112337',\n",
       " 'doc062200203368',\n",
       " 'doc062200210498',\n",
       " 'doc062200107753',\n",
       " 'doc062200108533',\n",
       " 'doc062200206242',\n",
       " 'doc062200108726',\n",
       " 'doc062200209842',\n",
       " 'doc062200103530',\n",
       " 'doc062200205548',\n",
       " 'doc062200108031',\n",
       " 'doc062200105417',\n",
       " 'doc062200107961',\n",
       " 'doc062200116046',\n",
       " 'doc062200110345',\n",
       " 'doc062200100832',\n",
       " 'doc062200108970',\n",
       " 'doc062200201425',\n",
       " 'doc062200203247',\n",
       " 'doc062200200456',\n",
       " 'doc062200108525',\n",
       " 'doc062200201814',\n",
       " 'doc062200110554',\n",
       " 'doc062200111415',\n",
       " 'doc062200108501',\n",
       " 'doc062200104801',\n",
       " 'doc062200116719',\n",
       " 'doc062200106598',\n",
       " 'doc062200202169',\n",
       " 'doc062200209516',\n",
       " 'doc062200200582',\n",
       " 'doc062200110056',\n",
       " 'doc062200202832',\n",
       " 'doc062200115516',\n",
       " 'doc062200205284',\n",
       " 'doc062200116610',\n",
       " 'doc062200103553',\n",
       " 'doc062200101811',\n",
       " 'doc062200102981',\n",
       " 'doc062200203725',\n",
       " 'doc062200107924',\n",
       " 'doc062200202820',\n",
       " 'doc062200204217',\n",
       " 'doc062200208243',\n",
       " 'doc062200204893',\n",
       " 'doc062200111481',\n",
       " 'doc062200205577',\n",
       " 'doc062200102169',\n",
       " 'doc062200109106',\n",
       " 'doc062200204311',\n",
       " 'doc062200202911',\n",
       " 'doc062200106876',\n",
       " 'doc062200207178',\n",
       " 'doc062200108325',\n",
       " 'doc062200108817',\n",
       " 'doc062200102881',\n",
       " 'doc062200210239',\n",
       " 'doc062200202165',\n",
       " 'doc062200100136',\n",
       " 'doc062200100267',\n",
       " 'doc062200204426',\n",
       " 'doc062200201314',\n",
       " 'doc062200108478',\n",
       " 'doc062200107425',\n",
       " 'doc062200112480',\n",
       " 'doc062200103116',\n",
       " 'doc062200207290',\n",
       " 'doc062200109191',\n",
       " 'doc062200111392',\n",
       " 'doc062200103799',\n",
       " 'doc062200110386',\n",
       " 'doc062200100242',\n",
       " 'doc062200107245',\n",
       " 'doc062200204426',\n",
       " 'doc062200104444',\n",
       " 'doc062200112710',\n",
       " 'doc062200109278',\n",
       " 'doc062200116442',\n",
       " 'doc062200106134',\n",
       " 'doc062200111057',\n",
       " 'doc062200201776',\n",
       " 'doc062200200341',\n",
       " 'doc062200116518',\n",
       " 'doc062200107472',\n",
       " 'doc062200103409',\n",
       " 'doc062200111571',\n",
       " 'doc062200208065',\n",
       " 'doc062200210380',\n",
       " 'doc062200106002',\n",
       " 'doc062200100855',\n",
       " 'doc062200204020',\n",
       " 'doc062200105343',\n",
       " 'doc062200211211',\n",
       " 'doc062200116403',\n",
       " 'doc062200211136',\n",
       " 'doc062200207499',\n",
       " 'doc062200200361',\n",
       " 'doc062200109191',\n",
       " 'doc062200202964',\n",
       " 'doc062200115749',\n",
       " 'doc062200108168',\n",
       " 'doc062200210654',\n",
       " 'doc062200116030',\n",
       " 'doc062200106776',\n",
       " 'doc062200107863',\n",
       " 'doc062200109567',\n",
       " 'doc062200115181',\n",
       " 'doc062200102860',\n",
       " 'doc062200100732',\n",
       " 'doc062200117168',\n",
       " 'doc062200109235',\n",
       " 'doc062200107653',\n",
       " 'doc062200211846',\n",
       " 'doc062200207587',\n",
       " 'doc062200105555',\n",
       " 'doc062200203074',\n",
       " 'doc062200205983',\n",
       " 'doc062200115749',\n",
       " 'doc062200200675',\n",
       " 'doc062200209794',\n",
       " 'doc062200210510',\n",
       " 'doc062200100850',\n",
       " 'doc062200104019',\n",
       " 'doc062200112999',\n",
       " 'doc062200203029',\n",
       " 'doc062200114760',\n",
       " 'doc062200104768',\n",
       " 'doc062200205221',\n",
       " 'doc062200205389',\n",
       " 'doc062200113805',\n",
       " 'doc062200100914',\n",
       " 'doc062200104110',\n",
       " 'doc062200105993',\n",
       " 'doc062200106734',\n",
       " 'doc062200108940',\n",
       " 'doc062200103500',\n",
       " 'doc062200200470',\n",
       " 'doc062200102280',\n",
       " 'doc062200203056',\n",
       " 'doc062200211681',\n",
       " 'doc062200106610',\n",
       " 'doc062200100952',\n",
       " 'doc062200202459',\n",
       " 'doc062200111176',\n",
       " 'doc062200109047',\n",
       " 'doc062200200630',\n",
       " 'doc062200102131',\n",
       " 'doc062200200046',\n",
       " 'doc062200111129',\n",
       " 'doc062200206873',\n",
       " 'doc062200112865',\n",
       " 'doc062200104423',\n",
       " 'doc062200206421',\n",
       " 'doc062200113614',\n",
       " 'doc062200106985',\n",
       " 'doc062200103449',\n",
       " 'doc062200113890',\n",
       " 'doc062200209806',\n",
       " 'doc062200100604',\n",
       " 'doc062200207652',\n",
       " 'doc062200104706',\n",
       " 'doc062200210720',\n",
       " 'doc062200204608',\n",
       " 'doc062200111745',\n",
       " 'doc062200205611',\n",
       " 'doc062200115809',\n",
       " 'doc062200107906',\n",
       " 'doc062200207043',\n",
       " 'doc062200203692',\n",
       " 'doc062200203517',\n",
       " 'doc062200211514',\n",
       " 'doc062200109826',\n",
       " 'doc062200113167',\n",
       " 'doc062200110299',\n",
       " 'doc062200208516',\n",
       " 'doc062200106584',\n",
       " 'doc062200106090',\n",
       " 'doc062200111977',\n",
       " 'doc062200209218',\n",
       " 'doc062200104971',\n",
       " 'doc062200115869',\n",
       " 'doc062200202034',\n",
       " 'doc062200204155',\n",
       " 'doc062200206970',\n",
       " 'doc062200115125',\n",
       " 'doc062200201838',\n",
       " 'doc062200111658',\n",
       " 'doc062200103269',\n",
       " 'doc062200200712',\n",
       " 'doc062200210586',\n",
       " 'doc062200105461',\n",
       " 'doc062200211597',\n",
       " 'doc062200209382',\n",
       " 'doc062200205016',\n",
       " 'doc062200201419',\n",
       " 'doc062200109054',\n",
       " 'doc062200204608',\n",
       " 'doc062200100922',\n",
       " 'doc062200115653',\n",
       " 'doc062200114004',\n",
       " 'doc062200205984',\n",
       " 'doc062200100123',\n",
       " 'doc062200111878',\n",
       " 'doc062200103316',\n",
       " 'doc062200204092',\n",
       " 'doc062200109381',\n",
       " 'doc062200111364',\n",
       " 'doc062200204161',\n",
       " 'doc062200111369',\n",
       " 'doc062200209877',\n",
       " 'doc062200200427',\n",
       " 'doc062200204349',\n",
       " 'doc062200115069',\n",
       " 'doc062200108947',\n",
       " 'doc062200110223',\n",
       " 'doc062200210713',\n",
       " 'doc062200116769',\n",
       " 'doc062200206176',\n",
       " 'doc062200100896',\n",
       " 'doc062200211798',\n",
       " 'doc062200208380',\n",
       " 'doc062200101665',\n",
       " 'doc062200117218',\n",
       " 'doc062200101302',\n",
       " 'doc062200100853',\n",
       " 'doc062200104428',\n",
       " 'doc062200100242',\n",
       " 'doc062200201629',\n",
       " 'doc062200205502',\n",
       " 'doc062200100374',\n",
       " 'doc062200207459',\n",
       " 'doc062200114997',\n",
       " 'doc062200105531',\n",
       " 'doc062200106924',\n",
       " 'doc062200205466',\n",
       " 'doc062200207247',\n",
       " 'doc062200113944',\n",
       " 'doc062200115710',\n",
       " 'doc062200104367',\n",
       " 'doc062200209063',\n",
       " 'doc062200102549',\n",
       " 'doc062200203956',\n",
       " 'doc062200114354',\n",
       " 'doc062200112504',\n",
       " 'doc062200107625',\n",
       " 'doc062200103467',\n",
       " 'doc062200209538',\n",
       " 'doc062200208871',\n",
       " 'doc062200100089',\n",
       " 'doc062200109589',\n",
       " 'doc062200204846',\n",
       " 'doc062200211635',\n",
       " 'doc062200101013',\n",
       " 'doc062200205389',\n",
       " 'doc062200115915',\n",
       " 'doc062200202731',\n",
       " 'doc062200101786',\n",
       " 'doc062200106215',\n",
       " 'doc062200205733',\n",
       " 'doc062200116046',\n",
       " 'doc062200206456',\n",
       " 'doc062200115329',\n",
       " 'doc062200110241',\n",
       " 'doc062200111445',\n",
       " 'doc062200114788',\n",
       " 'doc062200206566',\n",
       " 'doc062200207779',\n",
       " 'doc062200201169',\n",
       " 'doc062200201998',\n",
       " 'doc062200105597',\n",
       " 'doc062200201890',\n",
       " 'doc062200103481',\n",
       " 'doc062200113873',\n",
       " 'doc062200113116',\n",
       " 'doc062200211589',\n",
       " 'doc062200206482',\n",
       " 'doc062200201542',\n",
       " 'doc062200101318',\n",
       " 'doc062200116356',\n",
       " 'doc062200201890',\n",
       " 'doc062200201743',\n",
       " 'doc062200203897',\n",
       " 'doc062200113236',\n",
       " 'doc062200110361',\n",
       " 'doc062200103382',\n",
       " 'doc062200114575',\n",
       " 'doc062200205929',\n",
       " 'doc062200203821',\n",
       " 'doc062200109892',\n",
       " 'doc062200209097',\n",
       " 'doc062200109880',\n",
       " 'doc062200204175',\n",
       " 'doc062200116189',\n",
       " 'doc062200113867',\n",
       " 'doc062200203397',\n",
       " 'doc062200208544',\n",
       " 'doc062200201563',\n",
       " 'doc062200203211',\n",
       " 'doc062200200870',\n",
       " 'doc062200114764',\n",
       " 'doc062200210261',\n",
       " 'doc062200102554',\n",
       " 'doc062200106988',\n",
       " 'doc062200201394',\n",
       " 'doc062200106362',\n",
       " 'doc062200205139',\n",
       " 'doc062200208586',\n",
       " 'doc062200204217',\n",
       " 'doc062200105262',\n",
       " 'doc062200202820',\n",
       " 'doc062200116042',\n",
       " 'doc062200115732',\n",
       " 'doc062200205870',\n",
       " 'doc062200211555',\n",
       " 'doc062200111372',\n",
       " 'doc062200200940',\n",
       " 'doc062200203048',\n",
       " 'doc062200209218',\n",
       " 'doc062200206240',\n",
       " 'doc062200210389',\n",
       " 'doc062200100560',\n",
       " 'doc062200100460',\n",
       " 'doc062200103050',\n",
       " 'doc062200111382',\n",
       " 'doc062200115441',\n",
       " 'doc062200209969',\n",
       " 'doc062200113424',\n",
       " 'doc062200111956',\n",
       " 'doc062200102077',\n",
       " 'doc062200103490',\n",
       " 'doc062200100858',\n",
       " 'doc062200204995',\n",
       " 'doc062200101377',\n",
       " 'doc062200104216',\n",
       " 'doc062200110371',\n",
       " 'doc062200115911',\n",
       " 'doc062200206189',\n",
       " 'doc062200116388',\n",
       " 'doc062200105960',\n",
       " 'doc062200211253',\n",
       " 'doc062200115533',\n",
       " 'doc062200208095',\n",
       " 'doc062200208246',\n",
       " 'doc062200204608',\n",
       " 'doc062200111979',\n",
       " 'doc062200208518',\n",
       " 'doc062200115892',\n",
       " 'doc062200103322',\n",
       " 'doc062200101259',\n",
       " 'doc062200203491',\n",
       " 'doc062200200762',\n",
       " 'doc062200205770',\n",
       " 'doc062200106191',\n",
       " 'doc062200116060',\n",
       " 'doc062200113707',\n",
       " 'doc062200107837',\n",
       " 'doc062200102754',\n",
       " 'doc062200113503',\n",
       " 'doc062200114693',\n",
       " 'doc062200104253',\n",
       " 'doc062200204523',\n",
       " 'doc062200109563',\n",
       " 'doc062200113829',\n",
       " 'doc062200104806',\n",
       " 'doc062200103682',\n",
       " 'doc062200103116',\n",
       " 'doc062200104359',\n",
       " 'doc062200205165',\n",
       " 'doc062200108715',\n",
       " 'doc062200207255',\n",
       " 'doc062200107374',\n",
       " 'doc062200107250',\n",
       " 'doc062200104246',\n",
       " 'doc062200202012',\n",
       " 'doc062200203450',\n",
       " 'doc062200108920',\n",
       " 'doc062200113716',\n",
       " 'doc062200211129',\n",
       " 'doc062200115575',\n",
       " 'doc062200204617',\n",
       " 'doc062200100472',\n",
       " 'doc062200102586',\n",
       " 'doc062200112651',\n",
       " 'doc062200206330',\n",
       " 'doc062200117318',\n",
       " 'doc062200203715',\n",
       " 'doc062200110681',\n",
       " 'doc062200104801',\n",
       " 'doc062200203844',\n",
       " 'doc062200107520',\n",
       " 'doc062200208995',\n",
       " 'doc062200102370',\n",
       " 'doc062200201859',\n",
       " 'doc062200111721',\n",
       " 'doc062200101778',\n",
       " 'doc062200211226',\n",
       " 'doc062200208801',\n",
       " 'doc062200211304',\n",
       " 'doc062200110468',\n",
       " 'doc062200113788',\n",
       " 'doc062200201843',\n",
       " 'doc062200108119',\n",
       " 'doc062200205624',\n",
       " 'doc062200114553',\n",
       " 'doc062200102137',\n",
       " 'doc062200211017',\n",
       " 'doc062200211253',\n",
       " 'doc062200102104',\n",
       " 'doc062200100726',\n",
       " 'doc062200108331',\n",
       " 'doc062200211565',\n",
       " 'doc062200103796',\n",
       " 'doc062200102094',\n",
       " 'doc062200202607',\n",
       " 'doc062200113262',\n",
       " 'doc062200208219',\n",
       " 'doc062200103240',\n",
       " 'doc062200207138',\n",
       " 'doc062200113414',\n",
       " 'doc062200108953',\n",
       " 'doc062200202720',\n",
       " 'doc062200105933',\n",
       " 'doc062200107393',\n",
       " 'doc062200109501',\n",
       " 'doc062200205215',\n",
       " 'doc062200102588',\n",
       " 'doc062200205529',\n",
       " 'doc062200207243',\n",
       " 'doc062200112801',\n",
       " 'doc062200108461',\n",
       " 'doc062200102848',\n",
       " 'doc062200112865',\n",
       " 'doc062200104423',\n",
       " 'doc062200111778',\n",
       " 'doc062200211714',\n",
       " 'doc062200200682',\n",
       " 'doc062200103674',\n",
       " 'doc062200101416',\n",
       " 'doc062200103218',\n",
       " 'doc062200208386',\n",
       " 'doc062200101608',\n",
       " 'doc062200106205',\n",
       " 'doc062200109808',\n",
       " 'doc062200103230',\n",
       " 'doc062200107719',\n",
       " 'doc062200110987',\n",
       " 'doc062200109740',\n",
       " 'doc062200205087',\n",
       " 'doc062200207028',\n",
       " 'doc062200112213',\n",
       " 'doc062200211719',\n",
       " 'doc062200108841',\n",
       " 'doc062200211117',\n",
       " 'doc062200106117',\n",
       " 'doc062200204252',\n",
       " 'doc062200108547',\n",
       " 'doc062200200013',\n",
       " 'doc062200204887',\n",
       " 'doc062200104989',\n",
       " 'doc062200207831',\n",
       " 'doc062200205731',\n",
       " 'doc062200209730',\n",
       " 'doc062200207777',\n",
       " 'doc062200103195',\n",
       " 'doc062200205028',\n",
       " 'doc062200202200',\n",
       " 'doc062200110778',\n",
       " 'doc062200105062',\n",
       " 'doc062200102834',\n",
       " 'doc062200109572',\n",
       " 'doc062200204310',\n",
       " 'doc062200105431',\n",
       " 'doc062200211051',\n",
       " 'doc062200203245',\n",
       " 'doc062200112245',\n",
       " 'doc062200202683',\n",
       " 'doc062200108674',\n",
       " 'doc062200106204',\n",
       " 'doc062200112642',\n",
       " 'doc062200116709',\n",
       " 'doc062200204544',\n",
       " 'doc062200102105',\n",
       " 'doc062200110392',\n",
       " 'doc062200103758',\n",
       " 'doc062200206217',\n",
       " 'doc062200110353',\n",
       " 'doc062200203827',\n",
       " 'doc062200113640',\n",
       " 'doc062200106007',\n",
       " 'doc062200200891',\n",
       " 'doc062200205076',\n",
       " 'doc062200204340',\n",
       " 'doc062200203136',\n",
       " 'doc062200200101',\n",
       " 'doc062200204237',\n",
       " 'doc062200114909',\n",
       " 'doc062200107214',\n",
       " 'doc062200116668',\n",
       " 'doc062200112370',\n",
       " 'doc062200114111',\n",
       " 'doc062200101007',\n",
       " 'doc062200204801']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q06223196', '0', 'doc062200205493', 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(relevant_documents[1])\n",
    "\n",
    "'doc062200205493' in run.get_top_documents('q06223196', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose threshold\n",
    "\n",
    "sorted_term_frequencies = sorted(term_frequencies, key=lambda x: x[1], reverse=True)\n",
    "highest_diff = {'amount': 0, 'position': None}\n",
    "\n",
    "# typescript algorithm translated\n",
    "    \n",
    "sorted_terms = [\n",
    "    ['car', 3],\n",
    "    ['will', 4]\n",
    "]\n",
    "\n",
    "highest_diff = {'amount': 0, 'position': 0}\n",
    "\n",
    "for i in range(len(sorted_terms)):\n",
    "    current_diff = sorted_terms[i][1] - sorted_terms[i + 1][1] if i != len(sorted_terms) - 1 else 0\n",
    "    highest_diff = {'amount': current_diff, 'position': i} if current_diff > highest_diff['amount'] else highest_diff\n",
    "\n",
    "print(highest_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
